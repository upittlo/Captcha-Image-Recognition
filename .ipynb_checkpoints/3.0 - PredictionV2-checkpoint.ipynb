{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Prediction model\n",
    "\n",
    "- including normal version and class version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {}
     ]
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "XMgbwmd27xkN",
    "outputId": "be69d278-632b-49cd-f908-b900de82900e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ELURNN\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "#from helpers import resize_to_fit\n",
    "from imutils import paths\n",
    "import numpy as np\n",
    "import imutils\n",
    "import cv2\n",
    "import pickle\n",
    "\n",
    "## model file\n",
    "recognition_model = \"captcha_model.hdf5\"\n",
    "\n",
    "### label file\n",
    "Label_model = \"model_labels.dat\"\n",
    "\n",
    "## put testing image here\n",
    "Testing_image_file = \"Testing_image\"\n",
    "\n",
    "## Load up the model label\n",
    "\n",
    "with open(Label_model,\"rb\") as f:\n",
    "    lb = pickle.load(f)\n",
    "    \n",
    "## Load the recognition model\n",
    "model = load_model(recognition_model)\n",
    "\n",
    "### read image from file\n",
    "image = cv2.imread(Testing_image_file+\"/image.jpg\")\n",
    "image = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "## Add extra padding to margin, color = white\n",
    "image = cv2.copyMakeBorder(image,20,20,20,20,cv2.BORDER_CONSTANT, value=(255,255,255))\n",
    "\n",
    "### threshold the image (convert to pure black and white)\n",
    "\n",
    "thresh = cv2.threshold(image,0,255,cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)[1]\n",
    "\n",
    "### find the contours (continuous blobs of pixels) \n",
    "contours = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "### Hack for compatibility with different OpenCV version\n",
    "contours = contours[0] if imutils.is_cv2() else contours[1]\n",
    "\n",
    "letter_image_regions = []\n",
    "### Make sure not greater than 6 letters\n",
    "letter_left = 6\n",
    "\n",
    "for contour in contours:\n",
    "    ### Get the bounding box\n",
    "    (x,y,w,h) = cv2.boundingRect(contour)\n",
    "    \n",
    "    if w > 10:\n",
    "        # Compare the width and height of the contour to detect letters that\n",
    "        # are conjoined into one chunk\n",
    "        if w >=125 and letter_left >=5:\n",
    "            letters_width = int(w / 5)\n",
    "            letter_image_regions.append((x, y, letters_width, h))\n",
    "            letter_image_regions.append((x + letters_width, y, letters_width, h))\n",
    "            letter_image_regions.append((x + letters_width+letters_width, y, letters_width, h))\n",
    "            letter_image_regions.append((x + letters_width+letters_width+letters_width, y, letters_width, h))\n",
    "            letter_image_regions.append((x + letters_width+letters_width+letters_width+letters_width, y, letters_width, h))\n",
    "\n",
    "            letter_left = letter_left - 5\n",
    "\n",
    "        elif w >=95 and letter_left >= 4:\n",
    "            letters_width = int(w / 4)\n",
    "            letter_image_regions.append((x, y, letters_width, h))\n",
    "            letter_image_regions.append((x + letters_width, y, letters_width, h))\n",
    "            letter_image_regions.append((x + letters_width+letters_width, y, letters_width, h))\n",
    "            letter_image_regions.append((x + letters_width+letters_width+letters_width, y, letters_width, h))\n",
    "\n",
    "            letter_left = letter_left - 4\n",
    "\n",
    "        elif w >68 and letter_left >= 3:\n",
    "            letters_width = int(w / 3)\n",
    "            letter_image_regions.append((x, y, letters_width, h))\n",
    "            letter_image_regions.append((x + letters_width, y, letters_width, h))\n",
    "            letter_image_regions.append((x + letters_width+letters_width, y, letters_width, h))\n",
    "\n",
    "            letter_left = letter_left - 3\n",
    "\n",
    "        elif w >=38 and letter_left >= 2:\n",
    "            half_width = int(w / 2)\n",
    "            letter_image_regions.append((x, y, half_width, h))\n",
    "            letter_image_regions.append((x + half_width, y, half_width, h))\n",
    "\n",
    "            letter_left = letter_left - 2\n",
    "\n",
    "\n",
    "\n",
    "        else:\n",
    "            letter_image_regions.append((x, y, w, h))\n",
    "            letter_left = letter_left - 1\n",
    "           \n",
    "    ### If the letters != 6, skip the image \n",
    "if len(letter_image_regions) == 6:\n",
    "    #print(len(letter_image_regions))\n",
    "    \n",
    "    ## Sort the letter image based on x coordinate\n",
    "    letter_image_regions = sorted(letter_image_regions,key = lambda x:x[0])\n",
    "    \n",
    "    ## Create an output image and a list to hold predicted letters\n",
    "    \n",
    "    output = cv2.merge([image]*3)\n",
    "    \n",
    "    predictions = []\n",
    "    \n",
    "    ## loop over the letters\n",
    "    for letter_bounding_box in letter_image_regions:\n",
    "        \n",
    "        x,y,w,h = letter_bounding_box\n",
    "        \n",
    "        ## Extract the letter from original image with 2-pixel margin around the edge\n",
    "        letter_image = image[y - 2:y + h + 2, x - 2:x + w + 2]\n",
    "        \n",
    "        ## Resize the letter to 20*20 for prediction\n",
    "        \n",
    "        letter_image = cv2.resize(letter_image,(20,20))\n",
    "        \n",
    "        ## Turn single image into a 4d array for keras model predict\n",
    "        letter_image = np.reshape(letter_image, (1,20,20,1))\n",
    "        \n",
    "        ## Predict the letters\n",
    "        prediction = model.predict(letter_image)\n",
    "        \n",
    "        ## Convert the one-hot-encoded prediction back to a normal letter\n",
    "        ## return a (1,) ndarray , use [0] to get value\n",
    "        letter = lb.inverse_transform(prediction)[0]\n",
    "        predictions.append(letter)\n",
    "        \n",
    "        # print the captcha text\n",
    "        \n",
    "    captcha_text = \"\".join(predictions)\n",
    "        \n",
    "    print(captcha_text)\n",
    "    \n",
    "    \n",
    "    \n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "            \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {}
     ]
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "pESwYZTJ7xkZ",
    "outputId": "d0cd53a7-1fa4-4bd0-aa43-da317b2887bd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## show the image \n",
    "cv2.imshow(\"Output\", image)\n",
    "cv2.waitKey()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OVGKFRqa7xkg"
   },
   "source": [
    "## Class version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "wfpxt3cY7xkh"
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "#from helpers import resize_to_fit\n",
    "from imutils import paths\n",
    "import numpy as np\n",
    "import imutils\n",
    "import cv2\n",
    "import pickle\n",
    "class Amazon_Captcha_Recognition:\n",
    "    \n",
    "    def __init__(self):\n",
    "        ## model file\n",
    "        self.recognition_model = \"captcha_model.hdf5\"\n",
    "        \n",
    "        ### label file\n",
    "        self.Label_model = \"model_labels.dat\"\n",
    "        \n",
    "        self.model = load_model(self.recognition_model)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def Captcha_Recognition(self,IMAGE_PATH):\n",
    "\n",
    "\n",
    "        ## Load up the model label\n",
    "\n",
    "        with open(self.Label_model,\"rb\") as f:\n",
    "            lb = pickle.load(f)\n",
    "\n",
    "        ## Load the recognition model\n",
    "        ### model = load_model(self.recognition_model)\n",
    "        model = self.model\n",
    "        ### read image from file\n",
    "        image = cv2.imread(IMAGE_PATH)\n",
    "        image = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        ## Add extra padding to margin, color = white\n",
    "        image = cv2.copyMakeBorder(image,20,20,20,20,cv2.BORDER_CONSTANT, value=(255,255,255))\n",
    "\n",
    "        ### threshold the image (convert to pure black and white)\n",
    "\n",
    "        thresh = cv2.threshold(image,0,255,cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)[1]\n",
    "\n",
    "        ### find the contours (continuous blobs of pixels) \n",
    "        contours = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        ### Hack for compatibility with different OpenCV version\n",
    "        contours = contours[0] if imutils.is_cv2() else contours[1]\n",
    "\n",
    "        letter_image_regions = []\n",
    "        ### Make sure not greater than 6 letters\n",
    "        letter_left = 6\n",
    "\n",
    "        for contour in contours:\n",
    "            ### Get the bounding box\n",
    "            (x,y,w,h) = cv2.boundingRect(contour)\n",
    "\n",
    "            if w > 10:\n",
    "                # Compare the width and height of the contour to detect letters that\n",
    "                # are conjoined into one chunk\n",
    "                if w >=125 and letter_left >=5:\n",
    "                    letters_width = int(w / 5)\n",
    "                    letter_image_regions.append((x, y, letters_width, h))\n",
    "                    letter_image_regions.append((x + letters_width, y, letters_width, h))\n",
    "                    letter_image_regions.append((x + letters_width+letters_width, y, letters_width, h))\n",
    "                    letter_image_regions.append((x + letters_width+letters_width+letters_width, y, letters_width, h))\n",
    "                    letter_image_regions.append((x + letters_width+letters_width+letters_width+letters_width, y, letters_width, h))\n",
    "\n",
    "                    letter_left = letter_left - 5\n",
    "\n",
    "                elif w >=95 and letter_left >= 4:\n",
    "                    letters_width = int(w / 4)\n",
    "                    letter_image_regions.append((x, y, letters_width, h))\n",
    "                    letter_image_regions.append((x + letters_width, y, letters_width, h))\n",
    "                    letter_image_regions.append((x + letters_width+letters_width, y, letters_width, h))\n",
    "                    letter_image_regions.append((x + letters_width+letters_width+letters_width, y, letters_width, h))\n",
    "\n",
    "                    letter_left = letter_left - 4\n",
    "\n",
    "                elif w >68 and letter_left >= 3:\n",
    "                    letters_width = int(w / 3)\n",
    "                    letter_image_regions.append((x, y, letters_width, h))\n",
    "                    letter_image_regions.append((x + letters_width, y, letters_width, h))\n",
    "                    letter_image_regions.append((x + letters_width+letters_width, y, letters_width, h))\n",
    "\n",
    "                    letter_left = letter_left - 3\n",
    "\n",
    "                elif w >=38 and letter_left >= 2:\n",
    "                    half_width = int(w / 2)\n",
    "                    letter_image_regions.append((x, y, half_width, h))\n",
    "                    letter_image_regions.append((x + half_width, y, half_width, h))\n",
    "\n",
    "                    letter_left = letter_left - 2\n",
    "\n",
    "\n",
    "\n",
    "                else:\n",
    "                    letter_image_regions.append((x, y, w, h))\n",
    "                    letter_left = letter_left - 1\n",
    "\n",
    "            ### If the letters != 6, skip the image \n",
    "        if len(letter_image_regions) == 6:\n",
    "            #print(len(letter_image_regions))\n",
    "\n",
    "            ## Sort the letter image based on x coordinate\n",
    "            letter_image_regions = sorted(letter_image_regions,key = lambda x:x[0])\n",
    "\n",
    "            ## Create an output image and a list to hold predicted letters\n",
    "\n",
    "            output = cv2.merge([image]*3)\n",
    "\n",
    "            predictions = []\n",
    "\n",
    "            ## loop over the letters\n",
    "            for letter_bounding_box in letter_image_regions:\n",
    "\n",
    "                x,y,w,h = letter_bounding_box\n",
    "\n",
    "                ## Extract the letter from original image with 2-pixel margin around the edge\n",
    "                letter_image = image[y - 2:y + h + 2, x - 2:x + w + 2]\n",
    "\n",
    "                ## Resize the letter to 20*20 for prediction\n",
    "\n",
    "                letter_image = cv2.resize(letter_image,(20,20))\n",
    "\n",
    "                ## Turn single image into a 4d array for keras model predict\n",
    "                letter_image = np.reshape(letter_image, (1,20,20,1))\n",
    "\n",
    "                ## Predict the letters\n",
    "                prediction = model.predict(letter_image)\n",
    "\n",
    "                ## Convert the one-hot-encoded prediction back to a normal letter\n",
    "                ## return a (1,) ndarray , use [0] to get value\n",
    "                letter = lb.inverse_transform(prediction)[0]\n",
    "                predictions.append(letter)\n",
    "\n",
    "                # print the captcha text\n",
    "\n",
    "            captcha_text = \"\".join(predictions)\n",
    "\n",
    "            return captcha_text\n",
    "        else:\n",
    "\n",
    "            return str(\"Error\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "Qt-CjZV27xkl"
   },
   "outputs": [],
   "source": [
    "obj = Amazon_Captcha_Recognition()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {}
     ]
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "K5mFmRnD7xko",
    "outputId": "e7d40dfe-4fb2-4d3d-cadb-f5006a9e5eb7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ELURNN'"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IMAGE_PATH = \"Testing_image/image.jpg\"\n",
    "obj.Captcha_Recognition(IMAGE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "U01fRJh-7xkr"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "fg6kE1287xku"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "name": "PredictionV2.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
